# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

services:
  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: [ "CMD", "etcdctl", "endpoint", "health" ]
      interval: 30s
      timeout: 20s
      retries: 3
  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "5044:9001"
      - "5043:9000"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
  milvus-standalone:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.4.6
    command: [ "milvus", "run", "standalone" ]
    security_opt:
      - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/milvus.yaml:/milvus/configs/milvus.yaml
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9091/healthz" ]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"
  attu:
    container_name: attu
    image: zilliz/attu:v2.4
    environment:
      MILVUS_URL: milvus-standalone:19530
    ports:
      - "3000:3000"
    depends_on:
      - "milvus-standalone"
  dataprep:
    image: registry.cn-hangzhou.aliyuncs.com/2456868764/dataprep:v0.1.0
    container_name: dataprep-milvus-server
    depends_on:
      - milvus-standalone
      - tei-embedding-service
    ports:
      - "6010:6010"
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      MILVUS_DB_HOST: milvus-standalone
      MILVUS_DB_PORT: 19530
      EMBEDDING_TYPE: TEI
      TEI_EMBEDDING_ENDPOINT: http://tei-embedding-service:80
      HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      DATA_ROOT_PATH: /data
    volumes:
      - "./data:/data"
  tei-embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: tei-embedding-server
    ports:
      - "6006:80"
    volumes:
      - "/models:/data"
    shm_size: 1g
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
    command: --model-id ${EMBEDDING_MODEL_ID} --auto-truncate
  retriever:
    image: registry.cn-hangzhou.aliyuncs.com/2456868764/retriever:v0.0.7
    container_name: retriever-milvus-server
    depends_on:
      - milvus-standalone
    ports:
      - "7000:7000"
    ipc: host
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      MILVUS_DB_HOST: milvus-standalone
      MILVUS_DB_PORT: 19530
      EMBEDDING_TYPE: TEI
      TEI_EMBEDDING_ENDPOINT: http://tei-embedding-service:80
      HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
    restart: unless-stopped
  tei-reranking-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: tei-reranking-server
    ports:
      - "8808:80"
    volumes:
      - "/models:/data"
    shm_size: 1g
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      HUGGINGFACEHUB_API_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      HF_HUB_DISABLE_PROGRESS_BARS: 1
      HF_HUB_ENABLE_HF_TRANSFER: 0
    command: --model-id ${RERANK_MODEL_ID} --auto-truncate
  tgi-service:
    image: ghcr.io/huggingface/text-generation-inference:sha-e4201f4-intel-cpu
    container_name: tgi-service
    ports:
      - "9009:80"
    volumes:
      - "/models:/data"
    shm_size: 1g
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
      HF_TOKEN: ${HUGGINGFACEHUB_API_TOKEN}
      HF_HUB_DISABLE_PROGRESS_BARS: 1
      HF_HUB_ENABLE_HF_TRANSFER: 0
    command: --model-id ${LLM_MODEL_ID} --cuda-graphs 0
  chatqna-xeon-backend-server:
    image: registry.cn-hangzhou.aliyuncs.com/2456868764/chatqna:v0.0.7
    container_name: chatqna-xeon-backend-server
    depends_on:
      - milvus-standalone
      - tei-embedding-service
      - dataprep
      - retriever
      - tei-reranking-service
      - tgi-service
    ports:
      - "8888:8888"
    environment:
      - no_proxy=${no_proxy}
      - https_proxy=${https_proxy}
      - http_proxy=${http_proxy}
      - MEGA_SERVICE_HOST_IP=chatqna-xeon-backend-server
      - EMBEDDING_SERVER_HOST_IP=tei-embedding-service
      - EMBEDDING_SERVER_PORT=${EMBEDDING_SERVER_PORT:-80}
      - RETRIEVER_SERVICE_HOST_IP=retriever
      - RERANK_SERVER_HOST_IP=tei-reranking-service
      - RERANK_SERVER_PORT=${RERANK_SERVER_PORT:-80}
      - LLM_SERVER_HOST_IP=tgi-service
      - LLM_SERVER_PORT=${LLM_SERVER_PORT:-80}
      - LLM_MODEL=${LLM_MODEL_ID}
      - LOGFLAG=${LOGFLAG}
    ipc: host
    restart: always
  chatqna-xeon-ui-server:
    image: ${REGISTRY:-opea}/chatqna-ui:${TAG:-latest}
    container_name: chatqna-xeon-ui-server
    depends_on:
      - chatqna-xeon-backend-server
    ports:
      - "5173:5173"
    environment:
      - no_proxy=${no_proxy}
      - https_proxy=${https_proxy}
      - http_proxy=${http_proxy}
    ipc: host
    restart: always
  chatqna-xeon-nginx-server:
    image: ${REGISTRY:-opea}/nginx:${TAG:-latest}
    container_name: chatqna-xeon-nginx-server
    depends_on:
      - chatqna-xeon-backend-server
      - chatqna-xeon-ui-server
    ports:
      - "${NGINX_PORT:-80}:80"
    environment:
      - no_proxy=${no_proxy}
      - https_proxy=${https_proxy}
      - http_proxy=${http_proxy}
      - FRONTEND_SERVICE_IP=chatqna-xeon-ui-server
      - FRONTEND_SERVICE_PORT=5173
      - BACKEND_SERVICE_NAME=chatqna
      - BACKEND_SERVICE_IP=chatqna-xeon-backend-server
      - BACKEND_SERVICE_PORT=8888
      - DATAPREP_SERVICE_IP=dataprep
      - DATAPREP_SERVICE_PORT=6007
    ipc: host
    restart: always

networks:
  default:
    driver: bridge
